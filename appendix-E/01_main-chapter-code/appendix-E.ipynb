{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.0.1\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0 # 4\n",
    "batch_size = 8 # 16\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([16, 120])\n",
      "Label batch dimensions torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 training batches\n",
      "10 validation batches\n",
      "19 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 22:21:54.616032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-31 22:21:54.624650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730384514.633990   61277 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730384514.636785   61277 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 22:21:54.647842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 48.75%\n",
      "Validation accuracy: 53.02%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 48.75%\n",
      "Validation accuracy: 53.02%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.205, Val loss 3.111\n",
      "Ep 1 (Step 000050): Train loss 0.394, Val loss 0.456\n",
      "Training accuracy: 86.25% | Validation accuracy: 86.25%\n",
      "Ep 2 (Step 000100): Train loss 0.113, Val loss 0.047\n",
      "Training accuracy: 96.25% | Validation accuracy: 100.00%\n",
      "Ep 3 (Step 000150): Train loss 0.173, Val loss 0.061\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000200): Train loss 0.011, Val loss 0.011\n",
      "Ep 4 (Step 000250): Train loss 0.039, Val loss 0.016\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000300): Train loss 0.004, Val loss 0.026\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training completed in 1.22 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.90%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
